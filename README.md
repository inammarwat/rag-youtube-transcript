# ğŸ¥ YouTube RAG Pipeline with Gemini

A modular **Retrieval-Augmented Generation (RAG)** system that ingests YouTube video transcripts, performs semantic chunking and embedding, and enables question answering using **Google Gemini**.

This project demonstrates a complete end-to-end LLM pipeline including:

- Data ingestion  
- Text preprocessing & chunking  
- Embedding generation  
- Vector search (FAISS)  
- Retrieval-Augmented Generation (RAG)  

---

## ğŸš€ Project Overview

Large Language Models (LLMs) struggle with long-context documents and external knowledge integration.  
This project implements a **RAG pipeline** over YouTube transcripts to provide accurate, context-aware answers.

The system workflow:

1. Extracts transcripts from YouTube
2. Cleans and preprocesses text
3. Splits text into semantic chunks
4. Generates embeddings
5. Stores embeddings in FAISS vector store
6. Retrieves relevant chunks
7. Uses Gemini to generate context-aware answers

---

## ğŸ—ï¸ Project Structure

```
youtube-rag-gemini/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_ingestion.ipynb
â”‚   â”œâ”€â”€ 02_chunking_analysis.ipynb
â”‚   â”œâ”€â”€ 03_embedding_retrieval.ipynb
â”‚   â””â”€â”€ 04_rag_pipeline.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transcripts/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ§  System Architecture

```
YouTube Video
      â†“
Transcript Extraction
      â†“
Text Cleaning
      â†“
Chunking
      â†“
Embedding Generation
      â†“
FAISS Vector Store
      â†“
Retriever
      â†“
Gemini LLM
      â†“
Final Answer
```

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- Google Gemini API
- LangChain
- FAISS (Vector Database)
- youtube-transcript-api
- python-dotenv
- uv (package manager)

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/youtube-rag-gemini.git
cd youtube-rag-gemini
```

---

### 2ï¸âƒ£ Create Virtual Environment (using uv)

```bash
uv venv
.venv\Scripts\activate   # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
uv pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Add Gemini API Key

Create a `.env` file in the root directory:

```
GEMINI_API_KEY=your_api_key_here
```

âš ï¸ Do NOT upload `.env` to GitHub.

---

## â–¶ï¸ Running the Pipeline

### Option 1 â€” Development Mode (Notebooks)

Run notebooks in the following order:

1. `01_data_ingestion.ipynb`
2. `02_chunking_analysis.ipynb`
3. `03_embedding_retrieval.ipynb`
4. `04_rag_pipeline.ipynb`

---

### Option 2 â€” Full Pipeline Execution

```bash
python main.py
```

---

## ğŸ§ª Example Usage

**Input Query:**
```
What is the main idea of the video?
```

**Output:**
```
The video explains ...
```

(Answer generated using retrieved transcript context.)

---

## ğŸ“Š Key Features

- Modular RAG pipeline
- Error-handled transcript ingestion
- Persistent transcript storage
- Semantic text chunking
- Vector similarity search
- Context-aware Gemini responses
- Reproducible project structure

---

## ğŸ” Security Notes

- `.env` is excluded from version control
- API keys are never stored in source code
- Vector stores are not committed to GitHub

---

## ğŸ“Œ Future Improvements

- Add Streamlit web interface
- Add RAG evaluation metrics
- Support multiple videos
- Hybrid retrieval (BM25 + embeddings)
- Convert into REST API
- Extend to Agentic RAG system

---

## ğŸ“ Academic Value

This project demonstrates practical understanding of:

- Retrieval-Augmented Generation (RAG)
- Vector databases
- Embedding models
- Prompt engineering
- LLM integration
- Modular pipeline design

It can be extended into research on:
- Ag
