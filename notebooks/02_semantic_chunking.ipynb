{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f6c5e2",
   "metadata": {},
   "source": [
    "# Notebook 02 – Text Chunking & Preprocessing\n",
    "\n",
    "## Objective\n",
    "Split long transcript text into manageable chunks for embedding and retrieval.\n",
    "\n",
    "## Input\n",
    "Clean transcript (.txt file)\n",
    "\n",
    "## Output\n",
    "List of text chunks ready for embedding\n",
    "\n",
    "## Methodology\n",
    "- Load transcript\n",
    "- Apply RecursiveCharacterTextSplitter\n",
    "- Analyze chunk distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82478cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting NeuralTranscript Chunking Pipeline ---\n",
      "✂️ Initializing Recursive Splitting (Size: 1000, Overlap: 200)...\n",
      "✅ Created 169 enriched chunks.\n",
      "\n",
      "--- CHUNK VALIDATION ---\n",
      "Metadata: {'source': 'Gfr50f6ZBvo', 'content_type': 'video_transcript', 'start_index': 0}\n",
      "Preview: the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROJECT: \n",
    "NeuralTranscript: A RAG-Based Semantic Search & Q&A System for YouTube Content\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "AUTHOR: Engr. Inam Ullah Khan\n",
    "Master's Student in Data Science | Al-Farabi Kazakh National University\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "# NEW: Import from the dedicated text-splitters package\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "VIDEO_ID = \"Gfr50f6ZBvo\"\n",
    "INPUT_PATH = f\"data/transcripts/{VIDEO_ID}.txt\"\n",
    "\n",
    "# RAG Hyperparameters\n",
    "CHUNK_SIZE = 1000   \n",
    "CHUNK_OVERLAP = 200 \n",
    "\n",
    "# --- 2. CORE PROCESSING FUNCTIONS ---\n",
    "\n",
    "def load_processed_transcript(file_path: str) -> str:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"❌ Transcript not found at {file_path}. Run Notebook 01 first.\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def create_enriched_chunks(text: str, source_id: str) -> list[Document]:\n",
    "    print(f\"✂️ Initializing Recursive Splitting (Size: {CHUNK_SIZE}, Overlap: {CHUNK_OVERLAP})...\")\n",
    "    \n",
    "    # Updated Splitter\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    "        add_start_index=True \n",
    "    )\n",
    "    \n",
    "    # Generate chunks as Document objects\n",
    "    # Note: Using create_documents is cleaner in the new API\n",
    "    enriched_docs = splitter.create_documents(\n",
    "        [text], \n",
    "        metadatas=[{\"source\": source_id, \"content_type\": \"video_transcript\"}]\n",
    "    )\n",
    "    \n",
    "    return enriched_docs\n",
    "\n",
    "# --- 3. EXECUTION PIPELINE ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"--- Starting NeuralTranscript Chunking Pipeline ---\")\n",
    "    \n",
    "    full_text = load_processed_transcript(INPUT_PATH)\n",
    "    chunked_docs = create_enriched_chunks(full_text, VIDEO_ID)\n",
    "    \n",
    "    print(f\"✅ Created {len(chunked_docs)} enriched chunks.\")\n",
    "    \n",
    "    # Preview\n",
    "    sample = chunked_docs[0]\n",
    "    print(f\"\\n--- CHUNK VALIDATION ---\\nMetadata: {sample.metadata}\\nPreview: {sample.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6489ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks safely persisted to data/chunked_docs.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the chunks so Notebook 03 can use them\n",
    "with open(\"data/chunked_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunked_docs, f)\n",
    "\n",
    "print(\"✅ Chunks safely persisted to data/chunked_docs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaeab99",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- Transcript was successfully split into 169 chunks.\n",
    "- Overlap ensures contextual continuity between adjacent chunks.\n",
    "- Chunk sizes are appropriate for embedding model context window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42255cee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The transcript was successfully segmented into semantically meaningful chunks using a recursive character-based strategy.\n",
    "The selected chunk size and overlap balance contextual coherence and computational efficiency.\n",
    "The resulting chunks are ready for embedding and vector storage in the next stage of the RAG pipeline.\n",
    "\n",
    "\n",
    "**Next step:** Embedding generation and similarity-based retrieval  \n",
    "(`03_vector_indexing.ipynb`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
