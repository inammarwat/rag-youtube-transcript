{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a2e480",
   "metadata": {},
   "source": [
    "# Data Ingestion: YouTube Video Transcripts\n",
    "\n",
    "This notebook handles the **data ingestion stage** of a Retrieval-Augmented Generation (RAG) pipeline.\n",
    "It focuses on extracting and cleaning **YouTube video transcripts**, which serve as a representative\n",
    "example of long-form, unstructured text data.\n",
    "\n",
    "The output of this notebook is a cleaned transcript that can be passed to downstream steps such as\n",
    "chunking, embedding, and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9117ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting NeuralTranscript Ingestion ---\n",
      "üì° Accessing YouTube API for Video ID: Gfr50f6ZBvo...\n",
      "üßπ Cleaning and unifying transcript text...\n",
      "üìä Stats: 133836 characters processed.\n",
      "üíæ Success! Cleaned transcript saved to: data/transcripts\\Gfr50f6ZBvo.txt\n",
      "\n",
      "üìù PREVIEW (First 250 chars):\n",
      "the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all b...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROJECT: NeuralTranscript: Semantic Search & Q&A for YouTube Content\n",
    "MODULE: 01_DATA_INGESTION\n",
    "-------------------------------------------------------------------------\n",
    "DESCRIPTION:\n",
    "This notebook serves as the entry point for the NeuralTranscript pipeline. \n",
    "It automates the extraction of spoken content from YouTube videos using \n",
    "the YouTube Transcript API. The data is cleaned and prepared for \n",
    "vectorization and semantic indexing.\n",
    "\n",
    "AUTHOR: Engr. Inam Ullah Khan\n",
    "Master's Student in Data Science | Al-Farabi Kazakh National University\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Any\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Video: Demis Hassabis (DeepMind CEO) on AI\n",
    "VIDEO_ID = \"Gfr50f6ZBvo\" \n",
    "OUTPUT_FOLDER = \"data/transcripts\"\n",
    "\n",
    "# --- 2. CORE FUNCTIONS ---\n",
    "\n",
    "def fetch_youtube_transcript(video_id: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Retrieves the raw transcript data using the latest API standards.\n",
    "    \n",
    "    Args:\n",
    "        video_id (str): The unique 11-character YouTube video ID.\n",
    "        \n",
    "    Returns:\n",
    "        List[Any]: Raw transcript segments containing text and timestamps.\n",
    "    \"\"\"\n",
    "    print(f\"üì° Accessing YouTube API for Video ID: {video_id}...\")\n",
    "    try:\n",
    "        # Initializing the API instance (v1.x.x compatibility)\n",
    "        api_instance = YouTubeTranscriptApi()\n",
    "        \n",
    "        # Fetching transcript and converting to standard list format\n",
    "        raw_data = api_instance.fetch(video_id).to_raw_data()\n",
    "        return raw_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: Could not retrieve transcript. Details: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_transcript_to_text(raw_transcript: List[Any]) -> str:\n",
    "    \"\"\"\n",
    "    Cleans and unifies transcript segments into a single cohesive string.\n",
    "    \n",
    "    Args:\n",
    "        raw_transcript (List[Any]): List of transcript dictionaries.\n",
    "        \n",
    "    Returns:\n",
    "        str: A cleaned block of text ready for NLP tasks.\n",
    "    \"\"\"\n",
    "    print(\"üßπ Cleaning and unifying transcript text...\")\n",
    "    \n",
    "    # Extract 'text' field while handling potential object/dict variability\n",
    "    text_segments = []\n",
    "    for segment in raw_transcript:\n",
    "        if isinstance(segment, dict):\n",
    "            text_segments.append(segment.get(\"text\", \"\"))\n",
    "        else:\n",
    "            text_segments.append(getattr(segment, 'text', \"\"))\n",
    "            \n",
    "    # Join segments and remove excess whitespace for cleaner processing\n",
    "    unified_text = \" \".join(text_segments).replace(\"  \", \" \").strip()\n",
    "    return unified_text\n",
    "\n",
    "def save_to_disk(text_content: str, filename: str):\n",
    "    \"\"\"\n",
    "    Persists the cleaned text to a local file for downstream processing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "        print(f\"üìÅ Created directory: {OUTPUT_FOLDER}\")\n",
    "        \n",
    "    file_path = os.path.join(OUTPUT_FOLDER, f\"{filename}.txt\")\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text_content)\n",
    "    \n",
    "    print(f\"üíæ Success! Cleaned transcript saved to: {file_path}\")\n",
    "\n",
    "# --- 3. MAIN PIPELINE EXECUTION ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"--- Starting NeuralTranscript Ingestion ---\")\n",
    "    \n",
    "    # Step 1: Extraction\n",
    "    raw_transcript_data = fetch_youtube_transcript(VIDEO_ID)\n",
    "    \n",
    "    if raw_transcript_data:\n",
    "        # Step 2: Transformation\n",
    "        final_text = process_transcript_to_text(raw_transcript_data)\n",
    "        \n",
    "        if final_text:\n",
    "            print(f\"üìä Stats: {len(final_text)} characters processed.\")\n",
    "            \n",
    "            # Step 3: Loading (Saving)\n",
    "            save_to_disk(final_text, VIDEO_ID)\n",
    "            \n",
    "            # Final Preview\n",
    "            print(f\"\\nüìù PREVIEW (First 250 chars):\\n{final_text[:250]}...\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Warning: Transcript was empty after processing.\")\n",
    "    else:\n",
    "        print(\"‚ùå Pipeline halted: No data to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f2709",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Successfully retrieved YouTube video transcript\n",
    "- Converted timestamped segments into clean long-form text\n",
    "- Stored transcript for downstream RAG processing\n",
    "\n",
    "**Next step:** Text chunking and preprocessing (`02_chunking_analysis.ipynb`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
