{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a69af9f",
   "metadata": {},
   "source": [
    "# Notebook 01 ‚Äì Data Ingestion\n",
    "\n",
    "## Objective\n",
    "Extract and preprocess YouTube transcripts for use in a Retrieval-Augmented Generation (RAG) pipeline.\n",
    "\n",
    "## Input\n",
    "YouTube Video ID\n",
    "\n",
    "## Output\n",
    "Clean transcript saved as .txt file\n",
    "\n",
    "## Methodology\n",
    "- Fetch transcript using youtube-transcript-api\n",
    "- Convert structured segments into continuous text\n",
    "- Save for downstream processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9117ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting NeuralTranscript Ingestion ---\n",
      "üì° Accessing YouTube API for Video ID: Gfr50f6ZBvo...\n",
      "üßπ Cleaning and unifying transcript text...\n",
      "üìä Stats: 133836 characters processed.\n",
      "üíæ Success! Cleaned transcript saved to: data/transcripts\\Gfr50f6ZBvo.txt\n",
      "\n",
      "üìù PREVIEW (First 250 chars):\n",
      "the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all b...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PROJECT: \n",
    "NeuralTranscript: A RAG-Based Semantic Search & Q&A System for YouTube Content\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "AUTHOR: Engr. Inam Ullah Khan\n",
    "Master's Student in Data Science | Al-Farabi Kazakh National University\n",
    "-------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Any\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Video: Demis Hassabis (DeepMind CEO) on AI\n",
    "VIDEO_ID = \"Gfr50f6ZBvo\" \n",
    "OUTPUT_FOLDER = \"data/transcripts\"\n",
    "\n",
    "# --- 2. CORE FUNCTIONS ---\n",
    "\n",
    "def fetch_youtube_transcript(video_id: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Retrieves the raw transcript data using the latest API standards.\n",
    "    \n",
    "    Args:\n",
    "        video_id (str): The unique 11-character YouTube video ID.\n",
    "        \n",
    "    Returns:\n",
    "        List[Any]: Raw transcript segments containing text and timestamps.\n",
    "    \"\"\"\n",
    "    print(f\"üì° Accessing YouTube API for Video ID: {video_id}...\")\n",
    "    try:\n",
    "        # Initializing the API instance (v1.x.x compatibility)\n",
    "        api_instance = YouTubeTranscriptApi()\n",
    "        \n",
    "        # Fetching transcript and converting to standard list format\n",
    "        raw_data = api_instance.fetch(video_id).to_raw_data()\n",
    "        return raw_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: Could not retrieve transcript. Details: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_transcript_to_text(raw_transcript: List[Any]) -> str:\n",
    "    \"\"\"\n",
    "    Cleans and unifies transcript segments into a single cohesive string.\n",
    "    \n",
    "    Args:\n",
    "        raw_transcript (List[Any]): List of transcript dictionaries.\n",
    "        \n",
    "    Returns:\n",
    "        str: A cleaned block of text ready for NLP tasks.\n",
    "    \"\"\"\n",
    "    print(\"üßπ Cleaning and unifying transcript text...\")\n",
    "    \n",
    "    # Extract 'text' field while handling potential object/dict variability\n",
    "    text_segments = []\n",
    "    for segment in raw_transcript:\n",
    "        if isinstance(segment, dict):\n",
    "            text_segments.append(segment.get(\"text\", \"\"))\n",
    "        else:\n",
    "            text_segments.append(getattr(segment, 'text', \"\"))\n",
    "            \n",
    "    # Join segments and remove excess whitespace for cleaner processing\n",
    "    unified_text = \" \".join(text_segments).replace(\"  \", \" \").strip()\n",
    "    return unified_text\n",
    "\n",
    "def save_to_disk(text_content: str, filename: str):\n",
    "    \"\"\"\n",
    "    Persists the cleaned text to a local file for downstream processing.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "        print(f\"üìÅ Created directory: {OUTPUT_FOLDER}\")\n",
    "        \n",
    "    file_path = os.path.join(OUTPUT_FOLDER, f\"{filename}.txt\")\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text_content)\n",
    "    \n",
    "    print(f\"üíæ Success! Cleaned transcript saved to: {file_path}\")\n",
    "\n",
    "# --- 3. MAIN PIPELINE EXECUTION ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"--- Starting NeuralTranscript Ingestion ---\")\n",
    "    \n",
    "    # Step 1: Extraction\n",
    "    raw_transcript_data = fetch_youtube_transcript(VIDEO_ID)\n",
    "    \n",
    "    if raw_transcript_data:\n",
    "        # Step 2: Transformation\n",
    "        final_text = process_transcript_to_text(raw_transcript_data)\n",
    "        \n",
    "        if final_text:\n",
    "            print(f\"üìä Stats: {len(final_text)} characters processed.\")\n",
    "            \n",
    "            # Step 3: Loading (Saving)\n",
    "            save_to_disk(final_text, VIDEO_ID)\n",
    "            \n",
    "            # Final Preview\n",
    "            print(f\"\\nüìù PREVIEW (First 250 chars):\\n{final_text[:250]}...\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Warning: Transcript was empty after processing.\")\n",
    "    else:\n",
    "        print(\"‚ùå Pipeline halted: No data to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f7eef",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- Transcript successfully retrieved without errors.\n",
    "- Total character count: 133836.\n",
    "- Transcript saved locally for downstream chunking.\n",
    "- No missing segments detected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3f2709",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The data ingestion stage successfully extracted and cleaned the YouTube transcript.\n",
    "The resulting text file will serve as the raw document for semantic chunking and embedding generation in subsequent stages of the RAG pipeline.\n",
    "This completes the first stage of the system architecture.\n",
    "\n",
    "**Next step:** Text chunking and preprocessing (`02_chunking_analysis.ipynb`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
