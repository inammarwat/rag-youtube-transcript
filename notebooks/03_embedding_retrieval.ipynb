{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0674540",
   "metadata": {},
   "source": [
    "# Embedding Generation and Semantic Retrieval\n",
    "\n",
    "This notebook implements the **embedding and retrieval stage** of the RAG pipeline.\n",
    "Chunked transcript data is converted into dense vector representations and indexed\n",
    "using a vector database to enable semantic similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a196ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e28173",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/chunks\"\n",
    "VIDEO_ID = \"Gfr50f6ZBvo\"\n",
    "\n",
    "file_path = os.path.join(DATA_PATH, f\"{VIDEO_ID}_chunks.txt\")\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Chunk file loaded.\")\n",
    "print(f\"Total characters: {len(raw_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chunks(text: str) -> List[Document]:\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        if line.startswith(\"--- Chunk\"):\n",
    "            if current_chunk:\n",
    "                chunks.append(Document(page_content=\" \".join(current_chunk)))\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            if line.strip():\n",
    "                current_chunk.append(line.strip())\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(Document(page_content=\" \".join(current_chunk)))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "documents = parse_chunks(raw_text)\n",
    "\n",
    "print(f\"Total chunks loaded: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"Embedding model initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39832d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"Vector store created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the main topic discussed in this video?\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=4)\n",
    "\n",
    "print(\"Top retrieved chunks:\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"--- Result {i} ---\")\n",
    "    print(doc.page_content[:400])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_scores = vectorstore.similarity_search_with_score(query, k=4)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, start=1):\n",
    "    print(f\"Result {i} | Distance Score: {score:.4f}\")\n",
    "    print(doc.page_content[:300])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_PATH = \"../vectorstore/faiss_index\"\n",
    "\n",
    "os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
    "\n",
    "vectorstore.save_local(VECTOR_DB_PATH)\n",
    "\n",
    "print(f\"Vector store saved to: {VECTOR_DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vectorstore = FAISS.load_local(\n",
    "    VECTOR_DB_PATH,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "test_results = loaded_vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Vector store successfully reloaded.\")\n",
    "print(test_results[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011fb19",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- Dense embeddings capture semantic similarity effectively for long-form transcripts.\n",
    "- FAISS provides fast and reliable nearest-neighbor retrieval.\n",
    "- Retrieved chunks are contextually aligned with the query, validating the chunking strategy.\n",
    "\n",
    "The vector store is now ready to be integrated with an LLM for answer generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadb332",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Generated dense embeddings for transcript chunks\n",
    "- Indexed chunks using FAISS vector database\n",
    "- Validated semantic retrieval through similarity search\n",
    "- Persisted vector store for reuse\n",
    "\n",
    "**Next step:** Retrieval-Augmented Generation using an LLM  \n",
    "(`04_rag_pipeline.ipynb`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
